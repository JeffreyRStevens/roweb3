---
slug: ropensci-news
title: Latest rOpenSci News Digest
author:
  - The rOpenSci Team
date: '2021-03-15'
tags:
  - newsletter
description: keywords bla
output:
  html_document:
    keep_md: yes
params:
  last_newsletter: "2021-01-01"
---

```{r setup, include=FALSE}
library("magrittr")
library("rlang")
last_newsletter <- anytime::anytime(params$last_newsletter)
knitr::opts_chunk$set(echo = FALSE)
url <- sprintf(
    "/blog/%s/%s/%s/%s",
    lubridate::year(last_newsletter),
    stringr::str_pad(lubridate::month(last_newsletter), 2, "0", side = "left"),
    stringr::str_pad(lubridate::day(last_newsletter), 2, "0", side = "left"),
    rmarkdown::yaml_front_matter(knitr::current_input())$slug
    )
```

Dear rOpenSci friends, it's time for our monthly news roundup!
Yes, the latest one was on `r as.character(last_newsletter)`.
Some housekeeping first:
We've been changing the infrastructure of our newsletter a bit so please update your RSS and JSON feeds to `https://ropensci.org/tags/newsletter/index.xml` and `https://ropensci.org/tags/newsletter/index.json`, respectively.
You can read this post [on our blog](`r url`).
Now let's dive into the activity at and around rOpenSci!

## rOpenSci HQ

TO BE CURATED BY HAND

Find out more [events](/events).

## Software :package:

### New packages

```{r new-packages, cache = TRUE}
tidy_package <- function(entry) {
  tibble::tibble(
    package = entry$name,
    description = entry$description,
    details = entry$details,
    on_cran = entry$on_cran,
    on_bioc = entry$on_bioc,
    onboarding = entry$onboarding,
    url = entry$url,
    maintainer = entry$maintainer # use desc for more info
    
  )
}

registry <- "https://raw.githubusercontent.com/ropensci/roregistry/gh-pages/registry.json" %>%
  jsonlite::read_json() %>%
  purrr::pluck("packages") %>%
  purrr::map_df(tidy_package)
  
commits <- gh::gh(
  "GET /repos/{owner}/{repo}/commits",
  owner = "ropensci",
  repo = "roregistry",
  since = sprintf(
    "%s-%s-%sT00:00:00Z",
    lubridate::year(last_newsletter),
    stringr::str_pad(lubridate::month(last_newsletter), 2, "0", side = "left"),
    stringr::str_pad(lubridate::day(last_newsletter), 2, "0", side = "left")
  ),
  until = sprintf(
    "%s-%s-%sT00:00:00Z",
    lubridate::year(last_newsletter),
    stringr::str_pad(lubridate::month(last_newsletter), 2, "0", side = "left"),
    stringr::str_pad(lubridate::day(last_newsletter) + 1, 2, "0", side = "left")
  )
)

empty <- TRUE
i <- length(commits)
while (empty == TRUE) {
  old <- "https://raw.githubusercontent.com/ropensci/roregistry/%s/packages.json" %>%
    sprintf(commits[[i]]$sha) %>%
    jsonlite::read_json() %>%
    purrr::map_df(function(x) tibble::tibble(package = x$package, url = x$url, branch = x$branch))
  i <- i - 1
  if (nrow(old) > 100) {
    empty <- FALSE
  }
}

new <- dplyr::filter(
  registry,
  !package %in% old$package,
  !grepl("ropenscilabs\\/", url),
  !grepl("ropensci-archive\\/", url)
)
```


The following `r nrow(new)` package`r if(nrow(new)>1) "s"` recently became a part of our software suite:

```{r, results='asis', cache = TRUE}
packages <- split(new, seq(nrow(new)))
present_one <- function(package) {
  url_parts <- urltools::url_parse(package$url)
  desc_link <- gh::gh(
    "/repos/{owner}/{repo}/contents/{path}",
    owner = strsplit(url_parts$path, "\\/")[[1]][1],
    repo = strsplit(url_parts$path, "\\/")[[1]][2],
    path = "DESCRIPTION"
  ) %>%
    purrr::pluck("download_url")
  withr::with_tempfile(
    "tf", {
      download.file(desc_link, tf) 
      desc <<- desc::desc(file = tf)
    }
  )
  # as in pkgdown
  authors <- unclass(desc$get_authors())
  aut <- purrr::keep(authors, function(x) {any( x$role %in% "aut") && all(x$role != "cre") })
  aut <- purrr::map_chr(aut, function(x) paste(x$given, x$family))
  rev <- purrr::keep(authors, function(x) {any( x$role %in% "rev") && all(x$role != "cre") })
  rev <- purrr::map_chr(rev, function(x) paste(x$given, x$family))
  maintainer <- purrr::keep(authors, function(x) {any( x$role %in% "cre") })
  maintainer <- paste(c(maintainer[[1]]$given, maintainer[[1]]$family), collapse = " ")
  
  author_string <- sprintf("developed by %s", maintainer)
  
  if (length(aut) > 0) {
    author_string <- paste0(author_string, sprintf(" together with %s", toString(aut)))
  } 
  
  string <- sprintf(
    "[%s](https://docs.ropensci.org/%s), %s: %s. ",
    package$package, 
    package$package, 
    author_string,
    stringr::str_remove(stringr::str_squish(package$details), "\\.$")
  )
  
  if (package$on_cran) {
    string <- paste0(
      string, 
      sprintf(
        " It is available on [CRAN]( https://CRAN.R-project.org/package=%s). ",
        package$package
      )
    )
  }
  if (package$on_bioc) {
    string <- paste0(
      string, sprintf(
        " It is available on [Bioconductor](https://bioconductor.org/packages/%s/). ",
        package$package
      )
    )
  }
  if (nzchar(package$onboarding)) {
    string <- paste0(string, sprintf("It has been [reviewed](%s)", package$onboarding))
    if (length(rev) > 0) {
      string <- paste0(string, sprintf(" by %s.", toString(rev)))
    } else {
      string <- paste0(string, ".")
    }
  }
  
  paste("+", string)

}
text <- purrr::map_chr(
  packages,
  present_one
)
cat(paste0(text, collapse = "\n\n"))
```

Discover [more packages](/packages), read more about [Software Peer Review](/software-peer-review).

### New versions

```{r news, cache=TRUE}
registry <- dplyr::filter(
  registry,
  !grepl("ropenscilabs\\/", url),
  !grepl("ropensci-archive\\/", url)
)

registry <- registry %>%
  dplyr::rowwise() %>%
  dplyr::mutate(
  owner = strsplit(urltools::path(url), "/")[[1]][1],
  repo = strsplit(urltools::path(url), "/")[[1]][2]
) %>%
  dplyr::filter(
    !is.na(owner)
  )
packages <- split(registry, seq(nrow(registry)))
get_release <- function(repo) {
  info <- gh::gh(
    "GET /repos/{owner}/{repo}/releases",
    owner = repo$owner,
    repo = repo$repo,
    per_page = 1,
    description = repo$description
  )
  if(length(info) == 0 || anytime::anytime(info[[1]]$published_at) < last_newsletter) {
    return(NULL)
  }
  
  tibble::tibble(
    package = repo$package,
    version = info[[1]]$tag_name,
    url = info[[1]]$html_url,
    description = repo$description
  )
}
releases <- purrr::map_df(
  packages,
  get_release
)
releases <- split(releases, seq(nrow(releases)))
format_release <- function(release) {
  sprintf(
    '[%s](https://docs.ropensci/%s "%s") [%s](%s)',
    release$package,
    release$package,
    release$description,
    release$version,
    release$url
  )
}
all_releases <- purrr::map_chr(releases, format_release)
text <- toString(all_releases)
```

The following `r length(releases)` package`r if (length(releases) > 1) "s"` `r if (length(releases) > 1) "have" else "has"` had an update since the latest newsletter: `r text`.

We are only listing the most recent version.

## Software Peer Review

```{r software-review}

```

## On the blog

```{r blog}

parse_one_post <- function(path){
  lines <- suppressWarnings(readLines(path, encoding = "UTF-8"))
  yaml <- blogdown:::split_yaml_body(lines)$yaml
  yaml <- glue::glue_collapse(yaml, sep = "\n")
  yaml <- yaml::yaml.load(yaml)
  
  meta <- tibble::tibble(
    date = anytime::anydate(yaml$date),
    author = toString(yaml$author),
    title = yaml$title,
    software_peer_review = "Software Peer Review" %in% yaml$tags,
    tech_note = "tech notes" %in% yaml$tags && !"Software Peer Review" %in% yaml$tags,
    other = !"tech notes" %in% yaml$tags && !"Software Peer Review" %in% yaml$tags,
    twitterImg = yaml$twitterImg %||% "",
    twitterAlt = yaml$twitterAlt %||% "",
    description = yaml$description %||% "",
    newsletter = "newsletter" %in% yaml$tags,
    slug = yaml$slug
    )

  meta
}
paths <- fs::dir_ls("..", recurse = TRUE, glob = "*.md")
paths <- paths[!paths %in% c("../_index.md", "../2021-02-03-targets/raw_data_source.md",
  "../2021-02-03-targets/README.md")]
posts <- purrr::map_df(paths, parse_one_post)
posts <- dplyr::filter(posts, date >= as.Date(last_newsletter), !newsletter)
posts <- split(posts, seq(nrow(posts)))
format_post <- function(post) {
  url <- sprintf(
    "/blog/%s/%s/%s/%s",
    lubridate::year(post$date),
    stringr::str_pad(lubridate::month(post$date), 2, "0", side = "left"),
    stringr::str_pad(lubridate::day(post$date), 2, "0", side = "left"),
    post$slug
    )
  string <- sprintf("* [%s](%s) by %s", post$title, url, post$author)
  if (post$description != "") {
    string <- paste0(string, ". ", sub("\\?$", "", sub("\\!$", "", sub("\\.$", "", post$description), ".")), ".")
  } else {
    string <- paste0(string, ".")  
  }
  
  if (post$twitterImg != "") {
    string <- paste0(
      sprintf('{{< figure src="/%s" alt="%s" width="400" >}}\n\n', post$twitterImg, post$twitterAlt),
      string
    )
  }
  
  string
}
```

```{r, results='asis'}
cat("### Software Review\n\n")
cat(
  paste0(
    purrr::map_chr(posts[purrr::map_lgl(posts, "software_peer_review")], format_post),
    collapse = "\n\n"
  )
)
cat("\n\n")
cat("### Other topics\n\n")
cat(
  paste0(
    purrr::map_chr(posts[purrr::map_lgl(posts, "other")], format_post),
    collapse = "\n\n"
  )
)
cat("\n\n")
cat("### Tech Notes\n\n")
cat(
  paste0(
    purrr::map_chr(posts[purrr::map_lgl(posts, "tech_note")], format_post),
    collapse = "\n\n"
  )
)
cat("\n\n")
```

## Citations

```{r citations}
citations <- jsonlite::read_json("https://ropensci-org.github.io/ropensci_citations/citations_all_parts_clean.json")
years <- purrr::map_chr(citations, "year")
```

So far we found `r sum(years==lubridate::year(last_newsletter))` citations of our packages for `r lubridate::year(last_newsletter)`. 
In total our database contains `r length(citations)` citations that you can explore on our [citations page](/citations).
Thank you for citing our tools!

## Use cases

```{r usecases}
# rerun get_use_cases.R at the same time
usecases <- jsonlite::read_json("../../../data/usecases/usecases.json")
get_one_case <- function(usecase) {
  tibble::tibble(
    title = usecase$title,
    reporter = usecase$reporter,
    url = usecase$url,
    image = usecase$image,
    date = anytime::anydate(usecase$date)
  )
}
usecases <- purrr::map_df(usecases, get_one_case)
usecases <- dplyr::filter(usecases, date >= as.Date(last_newsletter))
usecases <- split(usecases, seq(nrow(usecases)))
```

`r length(usecases)` use cases of our packages and resources have been reported since the latest news digest.

```{r usecases2, results='asis'}
format_case <- function(usecase) {
  string <- sprintf("* [%s](%s). Reported by %s.", usecase$title, usecase$url, usecase$reporter)
  string
}
cat(
  paste0(
    purrr::map_chr(usecases, format_case),
    collapse = "\n\n"
  )
)
```

Explore [other use cases](/usecases) and [report your own](https://discuss.ropensci.org/c/usecases/10)!

## From the forum

TO BE CURATED BY HAND

## Call For maintainers

TO BE CURATED BY HAND

## Package development corner

TO BE CURATED BY HAND

## Last words

Thanks for reading! If you want to want to get involved with rOpenSci, check out our [Contributing Guide](https://contributing.ropensci.org) that can help direct you to the right place, whether you want to make code contributions, non-code contributions, or other things like sharing use cases.

If you haven't subscribed to our newsletter yet, you can [do so via a form](/news/). Until it's time for our next newsletter, you can keep in touch with us via our [website](/) and [Twitter account](https://twitter.com/ropensci).